{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import json\n",
    "from bidict import bidict\n",
    "import pickle\n",
    "import random\n",
    "from math import ceil\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/rali7/Tmp/solimanz/data/datasets/top7000/train_ids.pkl\", \"rb\")as f:\n",
    "    train_ids = pickle.load(f)\n",
    "with open(\"/data/rali7/Tmp/solimanz/data/datasets/top7000/test_ids.pkl\", \"rb\")as f:\n",
    "    test_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_job_title_sequences(data_path=\"/data/rali7/Tmp/solimanz/data/pickles/\",\n",
    "                                   save_path=\"/data/rali7/Tmp/solimanz/data/datasets/\",\n",
    "                                   offset=False, save=False):\n",
    "\n",
    "    print('Reading test and train ids...')\n",
    "    with open(\"/data/rali7/Tmp/solimanz/data/datasets/train_ids.pkl\", \"rb\")as f:\n",
    "        train_ids = pickle.load(f)\n",
    "    with open(\"/data/rali7/Tmp/solimanz/data/datasets/test_ids.pkl\", \"rb\")as f:\n",
    "        test_ids = pickle.load(f)\n",
    "\n",
    "    print('Loading dataframe...')\n",
    "    data = pd.read_pickle(os.path.join(data_path, \"clean_2017_11_28.pkl\"))\n",
    "    \n",
    "    func_counts = data.transformed.value_counts()\n",
    "    top_550 = func_counts[:550]    \n",
    "    \n",
    "    print('Building mapping between job title name and a job title id...')\n",
    "    job_titles = top_550.index.values\n",
    "    if offset:\n",
    "        title_id = {title: i + 1 for i, title in enumerate(job_titles)}\n",
    "    else:\n",
    "        title_id = {title: i for i, title in enumerate(job_titles)}\n",
    "\n",
    "    print('Getting list of job titles for every profile id')\n",
    "    func_series = data.groupby('_id')['transformed'].apply(lambda x: list(reversed(list(x))))\n",
    "\n",
    "    print('Building training data list...')\n",
    "    train_data = [[title_id[title] for title in func_series[i]] for i in train_ids]\n",
    "    print('Build test data...')\n",
    "    test_data = [[title_id[title] for title in func_series[i]] for i in test_ids]\n",
    "\n",
    "    print('dumping json...')\n",
    "    data = {\n",
    "        'title_to_id': title_id,\n",
    "        'train_data': train_data,\n",
    "        'test_data': test_data\n",
    "    }\n",
    "\n",
    "    if(save):\n",
    "        with open(os.path.join(save_path, \"title_seq.json\"), 'w') as f:\n",
    "            json.dump(data, f)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def build_data(dataset=\"train\"):\n",
    "\n",
    "    data = preprocess_job_title_sequences(offset=False, save=False)\n",
    "    examples = data[dataset + \"_data\"]\n",
    "    title_to_id = bidict(data[\"title_to_id\"])\n",
    "    vocab_size = len(title_to_id)\n",
    "    targets = np.zeros(len(examples))\n",
    "    X = np.zeros((len(examples), vocab_size))\n",
    "\n",
    "    for i, ex in enumerate(examples):\n",
    "        targets[i] = ex[-1]\n",
    "        for elem in ex[:-1]:\n",
    "            X[i][elem] += 1\n",
    "\n",
    "    return X, targets, title_to_id\n",
    "\n",
    "def multiomial_nb(X_train, train_targets, X_test, test_targets):\n",
    "    # Train\n",
    "    multi_nb = MultinomialNB()\n",
    "    print(\"Training Multinomial Naive Bayes...\")\n",
    "    multi_nb.fit(X_train, train_targets)\n",
    "\n",
    "    # Test\n",
    "    print(\"Running trained model on test dataset\")\n",
    "    predicted = multi_nb.predict(X_test)\n",
    "    acc = np.mean(predicted == test_targets)\n",
    "\n",
    "    print(\"Model Accuracy: \" + str(acc))\n",
    "    \n",
    "def bernoulli_nb(X_train, train_targets, X_test, test_targets):\n",
    "    # Train\n",
    "    nb = BernoulliNB()\n",
    "    print(\"Training Multinomial Naive Bayes...\")\n",
    "    nb.fit(X_train, train_targets)\n",
    "\n",
    "    # Test\n",
    "    print(\"Running trained model on test dataset\")\n",
    "    predicted = multi_nb.predict(X_test)\n",
    "    acc = np.mean(predicted == test_targets)\n",
    "\n",
    "    print(\"Model Accuracy: \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167582, 1838)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670328, 1839)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X(sequences, cv, counts=False, text=False):\n",
    "    if text:\n",
    "        #cv = CountVectorizer(binary=counts)\n",
    "        X = cv.transform(sequences)\n",
    "    else:\n",
    "        vocab_size = 550\n",
    "        X = np.zeros((len(sequences), vocab_size), dtype=np.int16)\n",
    "        for i, seq in enumerate(sequences):\n",
    "            for elem in seq:\n",
    "                if counts:\n",
    "                    X[i][elem] += 1\n",
    "                else:\n",
    "                    X[i][elem] = 1\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1_path = \"/data/rali7/Tmp/solimanz/data/datasets/top7000/1/\"\n",
    "ds1_file_name = \"title_sequences\"   \n",
    "with open(os.path.join(ds1_path, f\"{ds1_file_name}.json\"), 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_id = bidict(data[\"title_to_id\"])\n",
    "train = data[\"train_data\"]\n",
    "test = data[\"test_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = [[title_id.inv[i] for i in title_seq[:-1]] for title_seq in train]\n",
    "train_targets = [seq[-1] for seq in train]\n",
    "train_text = [\" \".join(title_seq).replace(\"_\", \" \") for title_seq in train_seq]\n",
    "\n",
    "test_seq = [[title_id.inv[i] for i in title_seq[:-1]] for title_seq in test]\n",
    "test_targets = [seq[-1] for seq in test]\n",
    "test_text = [\" \".join(title_seq).replace(\"_\", \" \") for title_seq in test_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_t = train_text + test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(binary=False)\n",
    "cv.fit(all_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = make_X(train_text, cv, counts=True, text=True) \n",
    "X_test = make_X(test_text, cv, counts=True, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nb = MultinomialNB()\n",
    "multi_nb.fit(X_train, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_acc(model, k=1):\n",
    "    preds = model.predict_proba(X_test)\n",
    "    sorted_args = (-preds).argsort(axis=1)[:,:k]\n",
    "    tt = np.tile(test_targets, (k,1)).T\n",
    "    acc = np.mean(np.sum(sorted_args == tt, axis=1))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 15.09\n",
      "top 2: 22.07\n",
      "top 3: 26.50\n",
      "top 4: 29.77\n",
      "top 5: 32.38\n"
     ]
    }
   ],
   "source": [
    "print(f\"acc: {top_k_acc(multi_nb, k=1)*100:.2f}\")\n",
    "print(f\"top 2: {top_k_acc(multi_nb, k=2)*100:.2f}\")\n",
    "print(f\"top 3: {top_k_acc(multi_nb, k=3)*100:.2f}\")\n",
    "print(f\"top 4: {top_k_acc(multi_nb, k=4)*100:.2f}\")\n",
    "print(f\"top 5: {top_k_acc(multi_nb, k=5)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 13.04\n",
      "top 2: 19.50\n"
     ]
    }
   ],
   "source": [
    "print(f\"acc: {top_k_acc(nb, k=1)*100:.2f}\")\n",
    "print(f\"top 2: {top_k_acc(nb, k=2)*100:.2f}\")\n",
    "print(f\"top 3: {top_k_acc(nb, k=3)*100:.2f}\")\n",
    "print(f\"top 4: {top_k_acc(nb, k=4)*100:.2f}\")\n",
    "print(f\"top 5: {top_k_acc(nb, k=5)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
