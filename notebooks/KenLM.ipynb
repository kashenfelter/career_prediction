{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "import kenlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KenLM Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data For KenLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path550 = \"/data/rali7/Tmp/solimanz/data/datasets/top550/\"\n",
    "path7k = \"/data/rali7/Tmp/solimanz/data/datasets/reduced7000/\"\n",
    "\n",
    "# Load data dicts\n",
    "with open(os.path.join(path550, \"jobid\", \"data.json\"), \"r\") as f:\n",
    "    data550 = json.load(f)\n",
    "with open(os.path.join(path7k, \"jobid\", \"data.json\"), \"r\") as f:\n",
    "    data7k = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_KenLM(train_data, dataset):\n",
    "    train_txt = \"\\n\".join([\" \".join([str(i) for i in dat[1]]) for dat in train_data])\n",
    "    \n",
    "    with open(f\"/data/rali7/Tmp/solimanz/data/datasets/ngrams/train_{dataset}.txt\", \"w\") as f:\n",
    "        f.write(train_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare_KenLM(data550['train_data'], '550')\n",
    "prepare_KenLM(data7k['train_data'], '7k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_7k = len(data7k['title_to_id'])\n",
    "n_550 = len(data550['title_to_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kenlm_predict(test, n_labels, n=2, model_binary='bigram550'):    \n",
    "    model = kenlm.Model(f\"../../kenlm/build/{model_binary}.binary\")\n",
    "    model_preds = np.zeros((len(test), n_labels))\n",
    "    \n",
    "    for j, seq in enumerate(test):\n",
    "        test_seq = seq[-(n-1):]\n",
    "        for i in range(n_labels):\n",
    "            model_preds[j][i] = model.score(\" \".join(test_seq + [str(i)]))      \n",
    "\n",
    "    return (-model_preds).argsort(axis=1)[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(test_data, n_labels, n, model):\n",
    "    preds = kenlm_predict(test_data, n_labels, n, model)\n",
    "    #filename = model.split('.')[0]\n",
    "    np.save(f'/data/rali7/Tmp/solimanz/data/ngram_preds/{model}.npy', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_KenLM_multi(models, data, n_labels):\n",
    "    test_data = [[str(i) for i in dat[1][:-1]] for dat in data[\"test_data\"]]\n",
    "    jobs = []\n",
    "    for n, model in models:\n",
    "        p = Process(target=worker, args=(test_data, n_labels, n, model))\n",
    "        jobs.append(p)\n",
    "        p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_550 = [(2, 'bigram550'),\n",
    "              (3, 'trigram550'),\n",
    "              (4, '4gram550'),\n",
    "              (5, '5gram550')]\n",
    "\n",
    "models_7k = [(2, 'bigram7k'),\n",
    "             (3, 'trigram7k'),\n",
    "             (4, '4gram7k'),\n",
    "             (5, '5gram7k')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_KenLM_multi(models_550, data550, n_550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_KenLM_multi(models_7k, data7k, n_7k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res550 = dict()\n",
    "res7k = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/rali7/Tmp/solimanz/data/pickles/res550.pkl', 'wb') as f:\n",
    "    pickle.dump(file=f, obj=res550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/rali7/Tmp/solimanz/data/pickles/res7k.pkl', 'wb') as f:\n",
    "    pickle.dump(file=f, obj=res7k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
